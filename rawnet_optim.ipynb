{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Requiremets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "if 1:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import librosa\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Add(nn.Module):\n",
    "    '''\n",
    "    Adds two tensors and returns the result\n",
    "    '''\n",
    "    def __init__(self,activation=None):\n",
    "        super(Add, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.digital = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x) != 2:\n",
    "            print('ERR: Num tensors to add',len(x))\n",
    "            raise\n",
    "#         return torch.stack(x,dim=0).sum(dim=0)\n",
    "        if self.activation is not None:\n",
    "            return self.activation(torch.stack(x,dim=0).sum(dim=0))\n",
    "        else:\n",
    "            return torch.stack(x,dim=0).sum(dim=0)\n",
    "        \n",
    "def model_summary(M, pt_191=False):\n",
    "    \"\"\"\n",
    "    This function provides summary of all the named classes in the model.\n",
    "    Use arguments pt_191=True for pytorch 1.9.1 usage, default pt_191 = False\n",
    "    Returns a dictionary of class names and usage count.\n",
    "    \"\"\"\n",
    "    def zero(): return 0\n",
    "    cdict = defaultdict(zero)\n",
    "    \n",
    "\n",
    "    for n,m in M.named_modules(remove_duplicate=True):\n",
    "        if isinstance(m,nn.Conv2d):\n",
    "            if M.get_submodule(n.rsplit('.',1)[0]).__class__.__name__ == 'CART':\n",
    "                cdict['CART_'+m.__class__.__name__]+=1\n",
    "                \n",
    "            else:\n",
    "                cdict[m.__class__.__name__]+=1\n",
    "                \n",
    "            \n",
    "        elif isinstance(m,(nn.ReLU,Add)) and hasattr(m,'digital'):\n",
    "            if m.digital:\n",
    "                cdict[m.__class__.__name__]+=1\n",
    "                \n",
    "            else:\n",
    "                cdict['CART_'+m.__class__.__name__]+=1\n",
    "                \n",
    "        else:\n",
    "             cdict[m.__class__.__name__]+=1\n",
    "        \n",
    "            \n",
    "    w_size=0        \n",
    "    for p in M.parameters():\n",
    "        w_size+=p.shape.numel()\n",
    "    cdict['Parameters'] = str(w_size/1e6)+'M'   \n",
    "        \n",
    "    return dict(cdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, directory, desired_duration, sample_rate=44100):\n",
    "        self.directory = directory\n",
    "        self.classes = sorted(os.listdir(directory))\n",
    "        self.audio_files = []\n",
    "        self.desired_duration = desired_duration\n",
    "        self.sample_rate=sample_rate\n",
    "\n",
    "        for i, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(directory, class_name)\n",
    "            for audio_file in os.listdir(class_path):\n",
    "                self.audio_files.append((os.path.join(class_path, audio_file), i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file, label = self.audio_files[idx]\n",
    "        # print(f\"Loading audio file: {audio_file}\")\n",
    "        # waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        waveform, sample_rate = librosa.load(audio_file, sr=None) \n",
    "        # print(f\"Loaded waveform shape: {waveform.shape}, Sample rate: {sample_rate}\")\n",
    "        waveform = self._process_waveform(waveform)\n",
    "        waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "        return waveform, label\n",
    "    \n",
    "    def _process_waveform(self, waveform):\n",
    "        if len(waveform) != self.desired_duration * self.sample_rate:\n",
    "            waveform = librosa.resample(waveform, orig_sr=len(waveform), target_sr=self.sample_rate)\n",
    "\n",
    "        if len(waveform) < self.desired_duration * self.sample_rate:\n",
    "            # print(\"Padding waveform...\")\n",
    "            pad_size = self.desired_duration * self.sample_rate - len(waveform)\n",
    "            waveform = torch.tensor(waveform).unsqueeze(0)  # Convert to torch tensor\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad_size)).squeeze(0)  # Pad and remove the added dimension\n",
    "        elif len(waveform) > self.desired_duration * self.sample_rate:\n",
    "            # print(\"Truncating waveform...\")\n",
    "            waveform = waveform[:self.desired_duration * self.sample_rate]\n",
    "\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/noise_identification/data/train'\n",
    "validation_dir = '/noise_identification/data/validate'\n",
    "test_dir = '/noise_identification/data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_duration = 6  # Duration in seconds\n",
    "train_dataset = AudioDataset(train_dir, desired_duration=desired_duration)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "validation_dataset = AudioDataset(validation_dir,desired_duration=desired_duration)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "test_dataset = AudioDataset(test_dir, desired_duration=desired_duration)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class RawNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import OrderedDict\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "\tdef __init__(self, nb_filts, first = False):\n",
    "\t\tsuper(Residual_block, self).__init__()\n",
    "\t\tself.first = first\n",
    "\t\t\n",
    "\t\tif not self.first:\n",
    "\t\t\tself.bn1 = nn.BatchNorm1d(num_features = nb_filts[0])\n",
    "\t\tself.lrelu = nn.LeakyReLU()\n",
    "\t\tself.lrelu_keras = nn.LeakyReLU(negative_slope=0.3)\n",
    "\n",
    "\t\tself.conv1 = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tstride = 1)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(num_features = nb_filts[1])\n",
    "\t\tself.conv2 = nn.Conv1d(in_channels = nb_filts[1],\n",
    "\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\tpadding = 1,\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tstride = 1)\n",
    "\n",
    "\t\tif nb_filts[0] != nb_filts[1]:\n",
    "\t\t\tself.downsample = True\n",
    "\t\t\tself.conv_downsample = nn.Conv1d(in_channels = nb_filts[0],\n",
    "\t\t\t\tout_channels = nb_filts[1],\n",
    "\t\t\t\tpadding = 0,\n",
    "\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\tstride = 1)\n",
    "\t\telse:\n",
    "\t\t\tself.downsample = False\n",
    "\t\tself.mp = nn.MaxPool1d(3)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tidentity = x\n",
    "\t\tif not self.first:\n",
    "\t\t\tout = self.bn1(x)\n",
    "\t\t\tout = self.lrelu_keras(out)\n",
    "\t\telse:\n",
    "\t\t\tout = x\n",
    "\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn2(out)\n",
    "\t\tout = self.lrelu_keras(out)\n",
    "\t\tout = self.conv2(out)\n",
    "\n",
    "\t\tif self.downsample:\n",
    "\t\t\tidentity = self.conv_downsample(identity)\n",
    "\t\t\n",
    "\t\tout += identity\n",
    "\t\tout = self.mp(out)\n",
    "\t\treturn out\n",
    "\n",
    "class RawNet(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(RawNet, self).__init__()\n",
    "\t\t#self.negative_k = d_args['negative_k']\n",
    "\t\tself.first_conv = nn.Conv1d(in_channels = 1,\n",
    "\t\t\tout_channels = 128,\n",
    "\t\t\tkernel_size = 3,\n",
    "\t\t\tpadding = 0,\n",
    "\t\t\tstride = 3)\n",
    "\t\tself.first_bn = nn.BatchNorm1d(num_features = 128)\n",
    "\t\tself.lrelu = nn.LeakyReLU()\n",
    "\t\tself.lrelu_keras = nn.LeakyReLU(negative_slope = 0.3)\n",
    "\n",
    "\t\tself.block0 = self._make_layer(nb_blocks = 2,\n",
    "\t\t\tnb_filts = [128,128],\n",
    "\t\t\tfirst = True)\n",
    "\t\tself.block1 = self._make_layer(nb_blocks = 4,\n",
    "\t\t\tnb_filts = [128, 256])\n",
    "\n",
    "\t\tself.bn_before_gru = nn.BatchNorm1d(num_features = 256)\n",
    "\t\tself.gru = nn.GRU(input_size = 256,\n",
    "\t\t\thidden_size = 1024,\n",
    "\t\t\tnum_layers = 1,\n",
    "\t\t\tbatch_first = True)\n",
    "\t\tself.fc1_gru = nn.Linear(in_features = 1024,\n",
    "\t\t\tout_features = 1024)\n",
    "\t\tself.fc2_gru = nn.Linear(in_features =1024,\n",
    "\t\t\tout_features = 3,\n",
    "\t\t\tbias = True)\n",
    "\n",
    "\tdef forward(self, x, y = 0, is_test=False):\n",
    "\t\t# print(x.shape)\n",
    "\t\tx = x.unsqueeze(1)\n",
    "\t\t# print(x.shape)\n",
    "\t\tx = self.first_conv(x)\n",
    "\t\tx = self.first_bn(x)\n",
    "\t\tx = self.lrelu_keras(x)\n",
    "\n",
    "\t\tx = self.block0(x)\n",
    "\t\tx = self.block1(x)\n",
    "\n",
    "\t\tx = self.bn_before_gru(x)\n",
    "\t\tx = self.lrelu_keras(x)\n",
    "\t\tx = x.permute(0, 2, 1)#(batch, filt, time) >> (batch, time, filt)\n",
    "\t\tx, _ = self.gru(x)\n",
    "\t\tx = x[:,-1,:]\n",
    "\t\tcode = self.fc1_gru(x)\n",
    "\t\tif is_test: return code\n",
    "\n",
    "\t\tcode_norm = code.norm(p=2,dim=1, keepdim=True) / 10.\n",
    "\t\tcode = torch.div(code, code_norm)\n",
    "\t\tout = self.fc2_gru(code)\n",
    "\t\treturn out\n",
    "\t\t'''\n",
    "\t\t#for future updates, bc_loss, h_loss\n",
    "\t\t#h_loss\n",
    "\t\tnorm = torch.norm(self.fc2_gru.weight, dim = 1, keepdim = True)\n",
    "\t\tnormed_weight = torch.div(self.fc2_gru.weight, norm)\n",
    "\t\tcos_output_tmp = torch.mm(code, normed_weight.t())\n",
    "\t\tcos_impo = cos_output_tmp.gather(1, y2)\n",
    "\t\tcos_target = cos_output_tmp.gather(1, y.view(-1, 1))\n",
    "\t\thard_negatives, _ = torch.topk(cos_impo, self.negative_k, dim=1, sorted=False)\n",
    "\t\thard_negatives = F.relu(hard_negatives, inplace=True)\n",
    "\t\ttrg_score = cos_target*-1.\n",
    "\t\th_loss = torch.log(1.+torch.exp(hard_negatives+trg_score).sum(dim=1))\n",
    "\t\treturn out, h_loss\n",
    "\t\t'''\n",
    "\n",
    "\tdef _make_layer(self, nb_blocks, nb_filts, first = False):\n",
    "\t\tlayers = []\n",
    "\t\t#def __init__(self, nb_filts, first = False):\n",
    "\t\tfor i in range(nb_blocks):\n",
    "\t\t\tfirst = first if i == 0 else False\n",
    "\t\t\tlayers.append(Residual_block(nb_filts = nb_filts,\n",
    "\t\t\t\tfirst = first))\n",
    "\t\t\tif i == 0: nb_filts[0] = nb_filts[1]\n",
    "\n",
    "\t\treturn nn.Sequential(*layers)\n",
    "\n",
    "\tdef summary(self, input_size, batch_size=-1, device=\"cuda\", print_fn = None):\n",
    "\t\tif print_fn == None: printfn = print\n",
    "\t\tmodel = self\n",
    "\t\n",
    "\t\tdef register_hook(module):\n",
    "\t\n",
    "\t\t\tdef hook(module, input, output):\n",
    "\t\t\t\tclass_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "\t\t\t\tmodule_idx = len(summary)\n",
    "\t\n",
    "\t\t\t\tm_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "\t\t\t\tsummary[m_key] = OrderedDict()\n",
    "\t\t\t\tsummary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "\t\t\t\tsummary[m_key][\"input_shape\"][0] = batch_size\n",
    "\t\t\t\tif isinstance(output, (list, tuple)):\n",
    "\t\t\t\t\tsummary[m_key][\"output_shape\"] = [\n",
    "\t\t\t\t\t\t[-1] + list(o.size())[1:] for o in output\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsummary[m_key][\"output_shape\"] = list(output.size())\n",
    "\t\t\t\t\tif len(summary[m_key][\"output_shape\"]) != 0:\n",
    "\t\t\t\t\t\tsummary[m_key][\"output_shape\"][0] = batch_size\n",
    "\t\n",
    "\t\t\t\tparams = 0\n",
    "\t\t\t\tif hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "\t\t\t\t\tparams += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "\t\t\t\t\tsummary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "\t\t\t\tif hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "\t\t\t\t\tparams += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "\t\t\t\tsummary[m_key][\"nb_params\"] = params\n",
    "\t\n",
    "\t\t\tif (\n",
    "\t\t\t\tnot isinstance(module, nn.Sequential)\n",
    "\t\t\t\tand not isinstance(module, nn.ModuleList)\n",
    "\t\t\t\tand not (module == model)\n",
    "\t\t\t):\n",
    "\t\t\t\thooks.append(module.register_forward_hook(hook))\n",
    "\t\n",
    "\t\tdevice = device.lower()\n",
    "\t\tassert device in [\n",
    "\t\t\t\"cuda\",\n",
    "\t\t\t\"cpu\",\n",
    "\t\t], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\t\n",
    "\t\tif device == \"cuda\" and torch.cuda.is_available():\n",
    "\t\t\tdtype = torch.cuda.FloatTensor\n",
    "\t\telse:\n",
    "\t\t\tdtype = torch.FloatTensor\n",
    "\t\tif isinstance(input_size, tuple):\n",
    "\t\t\tinput_size = [input_size]\n",
    "\t\tx = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "\t\tsummary = OrderedDict()\n",
    "\t\thooks = []\n",
    "\t\tmodel.apply(register_hook)\n",
    "\t\tmodel(*x)\n",
    "\t\tfor h in hooks:\n",
    "\t\t\th.remove()\n",
    "\t\n",
    "\t\tprint_fn(\"----------------------------------------------------------------\")\n",
    "\t\tline_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "\t\tprint_fn(line_new)\n",
    "\t\tprint_fn(\"================================================================\")\n",
    "\t\ttotal_params = 0\n",
    "\t\ttotal_output = 0\n",
    "\t\ttrainable_params = 0\n",
    "\t\tfor layer in summary:\n",
    "\t\t\t# input_shape, output_shape, trainable, nb_params\n",
    "\t\t\tline_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "\t\t\t\tlayer,\n",
    "\t\t\t\tstr(summary[layer][\"output_shape\"]),\n",
    "\t\t\t\t\"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "\t\t\t)\n",
    "\t\t\ttotal_params += summary[layer][\"nb_params\"]\n",
    "\t\t\ttotal_output += np.prod(summary[layer][\"output_shape\"])\n",
    "\t\t\tif \"trainable\" in summary[layer]:\n",
    "\t\t\t\tif summary[layer][\"trainable\"] == True:\n",
    "\t\t\t\t\ttrainable_params += summary[layer][\"nb_params\"]\n",
    "\t\t\tprint_fn(line_new)\n",
    "\t\n",
    "\t\t# assume 4 bytes/number (float on cuda).\n",
    "\t\ttotal_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
    "\t\ttotal_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
    "\t\ttotal_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
    "\t\ttotal_size = total_params_size + total_output_size + total_input_size\n",
    "\t\n",
    "\t\tprint_fn(\"================================================================\")\n",
    "\t\tprint_fn(\"Total params: {0:,}\".format(total_params))\n",
    "\t\tprint_fn(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "\t\tprint_fn(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "\t\tprint_fn(\"----------------------------------------------------------------\")\n",
    "\t\tprint_fn(\"Input size (MB): %0.2f\" % total_input_size)\n",
    "\t\tprint_fn(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
    "\t\tprint_fn(\"Params size (MB): %0.2f\" % total_params_size)\n",
    "\t\tprint_fn(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
    "\t\tprint_fn(\"----------------------------------------------------------------\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,val_loader, criterion, optimizer, num_epochs=10):\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {epoch_train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                val_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    end_time = time.time()  # Record end time\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss_history, label='Train Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), val_loss_history, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Loss')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc_history, label='Train Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(1, num_epochs + 1), val_acc_history, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate model size and number of parameters\n",
    "    model_size_mb = sum(p.numel() for p in model.parameters()) / (1024 * 1024)\n",
    "    num_parameters = count_parameters(model)\n",
    "    print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"Number of Parameters: {num_parameters}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'Rawnet.pth')\n",
    "    torch.save(model, \"Rawnet.pt\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    inference_end_time = time.time()\n",
    "    inference_time = inference_end_time - inference_start_time\n",
    "    print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "    \n",
    "    test_accuracy = correct / total\n",
    "    print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=test_dataset.classes))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix (Test)')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot classification report\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(pd.DataFrame.from_dict(classification_report(y_true, y_pred, target_names=test_dataset.classes, output_dict=True)), annot=True, cmap='Blues')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Classes')\n",
    "    plt.title('Classification Report (Test)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter space for Bayesian optimization\n",
    "search_space = [\n",
    "    Real(1e-6, 1e-2, name='learning_rate')\n",
    "]\n",
    "sample_rate= 44100\n",
    "\n",
    "results_file = \"optimization_results_rawnet.txt\"\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "@use_named_args(search_space)\n",
    "def optimize_model(learning_rate):\n",
    "    # Define model architecture and other necessary components\n",
    "    model = RawNet().to(device)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    weight_decay = 0.0001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model = train_model(model, train_loader, validation_loader, criterion, optimizer, num_epochs=50)\n",
    "    val_accuracy = validate_model(trained_model, validation_loader)\n",
    "\n",
    "    print(f\"Learning Rate: {learning_rate}, weight_decay: {weight_decay}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    with open(results_file, 'a') as f:\n",
    "        f.write(f\"Learning Rate: {learning_rate}, weight_decay: {weight_decay}, Validation Accuracy: {val_accuracy}\\n\")\n",
    "    \n",
    "    \n",
    "    # Return the validation accuracy as the optimization target\n",
    "    return -val_accuracy \n",
    "\n",
    "res_gp = gp_minimize(optimize_model, search_space, n_calls=15, random_state=1016)\n",
    "\n",
    "best_params = dict(zip(['learning_rate'], res_gp.x))\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Train model with best hyperparameters\n",
    "best_accuracy = -res_gp.fun\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RawNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model, criterion, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "weight_decay = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=res_gp.x[0], weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, validation_loader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_front_end_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
